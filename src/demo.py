#!/usr/bin/env python3
# ===========================================
# ECSA Refactored - Demo Script
# ===========================================
"""
Complete demonstration of the new Component architecture.
Shows how to use all implemented features:
- Lifecycle hooks
- Pydantic configurations
- Error handling
- Inter-component communication
- AsyncComponent API
- Middlewares
- Observability
- Testing
"""

import asyncio
import os
import sys
from pathlib import Path

# Add root directory to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from main import Agent, BaseEvent, ErrorEvent  # Import base types as well
from Events import InputEvent, GetContextRequest, StoreMessageRequest
from Components import (
    LLMComponent, LLMConfig,
    ContextComponent, ContextConfig,
    OutputComponent, OutputConfig,

    # Presets
    create_fast_llm_config,
    create_chatbot_config,

    # Add the missing ones directly
    create_creative_llm_config,
    create_analytical_llm_config,
    create_teacher_config,
)

# Import ComponentTestHarness directly from main
from main import ComponentTestHarness
from EventBus import EventBus

# Disable LLMFactory logging for cleaner demo output
import logging
logging.basicConfig(level=logging.WARNING)




async def demo_basic_agent():
    """
    Demo 1: Basic Functional Agent
    """
    print("\n" + "="*60)
    print("ğŸš€ DEMO 1: Basic Functional Agent")
    print("="*60)

    # Cria agent
    agent = Agent("demo_agent")

    # Adiciona componentes com configuraÃ§Ãµes personalizadas
    await agent.add_component(
        ContextComponent,
        config=create_chatbot_config()
    )

    # Usa config presets para LLM
    await agent.add_component(
        LLMComponent,
        config=create_fast_llm_config()
    )

    await agent.add_component(
        OutputComponent,
        config=OutputConfig(output_format="text")
    )

    # Inicializa agent (chama on_init de todos os componentes)
    await agent.init_all()

    print("âœ… Agent inicializado com 3 componentes!")

    # Simula input do usuÃ¡rio
    input_event = InputEvent(
        sender="user",
        target="demo_agent:ContextComponent",
        content="OlÃ¡! Como vocÃª estÃ¡?",
        session_id="demo_session"
    )

    print("ğŸ“¨ Enviando input do usuÃ¡rio...")

    # Processa o evento (passa por toda a pipeline)
    try:
        result_events = await agent.send_event(input_event)
        print(f"ğŸ“‹ Eventos emitidos: {len(result_events)}")

        for event in result_events:
            print(f"   â€¢ {event.type} -> {event.target}")

        # Demonstra calma inter-componente
        context_comp = agent.components["ContextComponent"]

        # Chama API AsyncComponent diretamente
        context_request = GetContextRequest(session_id="demo_session")
        context_response = await context_comp.request(context_request)

        print("\nğŸ’¬ Contexto da sessÃ£o:")
        print(f"   Total mensagens: {len(context_response.messages)}")
        print(f"   Ãšltima: {context_response.messages[-1]['content'][:50] if context_response.messages else 'Nenhuma'}")

    except Exception as e:
        print(f"âš ï¸ SimulaÃ§Ã£o ignorada (API key nÃ£o configurada?): {e}")

    # Finaliza agent
    await agent.shutdown_all()
    print("ğŸ›‘ Agent finalizado")

async def demo_component_testing():
    """
    Demo 2: Component Testing Harness
    """
    print("\n" + "="*60)
    print("ğŸ§ª DEMO 2: Component Testing Harness")
    print("="*60)

    # Cria componente em isolamento
    context_config = ContextConfig(
        connection_string="sqlite:///test.db"  # Banco de teste
    )
    context = ContextComponent(config=context_config)

    # Cria test harness
    harness = ComponentTestHarness(context)

    print("ğŸ§ª Testando ContextComponent isoladamente...")

    # Simula input event
    input_event = InputEvent(
        sender="test",
        target="test:ContextComponent",
        content="Hello world!",
        session_id="test_session_1"
    )

    # Executa teste
    result_events = await harness.send(input_event)

    print(f"ğŸ“¤ Eventos emitidos: {len(result_events)}")
    print(f"ğŸ“Š MÃ©tricas: {harness.get_metrics().model_dump()}")

    # Verifica se emitiu contexto
    context_events = [e for e in harness.sent_events if e.type == "context"]
    harness.assert_emitted("context", count=1)
    print("âœ… Teste passou: Contexto foi emitido")

    # Testa API AsyncComponent diretamente
    store_request = StoreMessageRequest(
        session_id="test_session_1",
        message_type="ai",
        content="OlÃ¡! Como posso ajudar?"
    )

    # Simula chamando como outro componente faria
    context.set_agent_ref(harness)  # Mock agent
    response = await context.request(store_request)
    print(f"ğŸ’¾ Store message result: {response.success}")

    # Reseta para novo teste
    harness.reset()
    print(f"ğŸ”„ ApÃ³s reset: {harness.get_metrics().events_received} eventos")

async def demo_component_features():
    """
    Demo 3: Recursos avanÃ§ados dos componentes
    """
    print("\n" + "="*60)
    print("âš¡ DEMO 3: Recursos AvanÃ§ados")
    print("="*60)

    # Cria componente com middlewares
    from Components.LLMComponent import LoggingMiddleware, RetryMiddleware

    llm_config = LLMConfig(
        llm_id="nonexistent_llm",  # Simula erro
        max_retries=2
    )

    llm = LLMComponent(config=llm_config)
    llm.middlewares = [LoggingMiddleware(), RetryMiddleware(max_retries=1)]

    harness = ComponentTestHarness(llm)

    print("ğŸ› ï¸ Testando middlewares e error handling...")

    # Testa error handling
    try:
        from Events import ContextEvent
        error_event = ContextEvent(
            sender="test",
            target="test:LLMComponent",
            formatted_prompt="Test prompt",
            session_id="error_test"
        )

        # Isso deve falhar mas ser tratado graciosamente
        await harness.send(error_event)

    except Exception as e:
        print(f"âš ï¸ Erro esperado: {type(e).__name__}")

    # Mostra mÃ©tricas apÃ³s erro
    metrics = harness.get_metrics()
    print(f"ğŸ“Š MÃ©tricas apÃ³s erro: {metrics.errors} erros, {metrics.events_received} eventos")

    # Mostra info do componente
    info = llm.get_info()
    print(f"â„¹ï¸ Config ativa: {info['config']['llm_id']}")
    print(f"ğŸ›¡ï¸ Middlewares: {info['middlewares']}")

async def demo_inter_component_call():
    """
    Demo 4: ComunicaÃ§Ã£o inter-componente
    """
    print("\n" + "="*60)
    print("ğŸ”— DEMO 4: ComunicaÃ§Ã£o Inter-Componente")
    print("="*60)

    # Cria agent minimal com dois componentes
    agent = Agent("inter_agent")

    # Context como AsyncComponent
    await agent.add_component(
        ContextComponent,
        config=ContextConfig(connection_string="sqlite:///inter.db")
    )

    # LLM que vai chamar context
    await agent.add_component(
        LLMComponent,
        config=create_fast_llm_config()
    )

    await agent.init_all()

    print("ğŸ”— Testando call_component()...")

    llm_comp = agent.components["LLMComponent"]

    # Simula LLM chamando context diretamente (nÃ£o via eventos)
    if hasattr(llm_comp, 'call_component'):
        try:
            context_request = GetContextRequest(session_id="call_test")
            response = await llm_comp.call_component("ContextComponent", context_request)

            print(f"âœ… Call direto funcionou: {response.success}")
            print(f"ğŸ“„ Mensagens recuperadas: {len(response.messages) if hasattr(response, 'messages') else 0}")

        except Exception as e:
            print(f"âš ï¸ Call falhou (API key?): {e}")

    await agent.shutdown_all()

async def demo_configuration_and_presets():
    """
    Demo 5: ConfiguraÃ§Ãµes e presets
    """
    print("\n" + "="*60)
    print("âš™ï¸ DEMO 5: ConfiguraÃ§Ãµes e Presets")
    print("="*60)

    print("ğŸ”§ ConfiguraÃ§Ãµes disponÃ­veis:")

    # LLM presets
    fast_config = create_fast_llm_config()
    creative_config = create_creative_llm_config()
    analytic_config = create_analytical_llm_config()

    print(f"  ğŸš€ Fast LLM: {fast_config.llm_id}, temp={fast_config.temperature}")
    print(f"  ğŸ¨ Creative LLM: {creative_config.llm_id}, temp={creative_config.temperature}")
    print(f"  ğŸ§  Analytical LLM: {analytic_config.llm_id}, temp={analytic_config.temperature}")

    # Context presets
    chatbot_config = create_chatbot_config()
    teacher_config = create_teacher_config()

    print("\nğŸ’¬ Context presets:")
    print(f"  ğŸ¤– Chatbot: {len(chatbot_config.initial_system_prompt)} chars prompt")
    print(f"  ğŸ‘¨â€ğŸ« Teacher: {len(teacher_config.initial_system_prompt)} chars prompt")

    # Demonstra validaÃ§Ã£o automÃ¡tica
    print("\nâœ… ValidaÃ§Ã£o Pydantic:")
    try:
        invalid_config = LLMConfig(llm_id=123)  # Tipo errado
    except Exception as e:
        print(f"  ğŸš« Erro capturado: {type(e).__name__} - llm_id deve ser string")

    print("  âœ… ConfiguraÃ§Ã£o vÃ¡lida criada automaticamente!")

async def demo_chatbot():
    """
    Demo 6: Chatbot funcional com memÃ³ria e tools
    """
    print("\n" + "="*60)
    print("ğŸ¤– DEMO 6: Chatbot com MemÃ³ria e Tools")
    print("="*60)

    # Define tools
    from langchain_core.tools import Tool

    def calculator(expression: str) -> str:
        """Calcula expressÃµes matemÃ¡ticas simples"""
        try:
            result = eval(expression)
            return f"Resultado: {result}"
        except Exception as e:
            return f"Erro no cÃ¡lculo: {e}"

    def search_web(query: str) -> str:
        """Busca na web (simulado)"""
        return f"Resultados para '{query}': [Dados simulados da web - implemente API real se necessÃ¡rio]"

    tools = [
        Tool(name="calculator", func=calculator, description="Calculadora para operaÃ§Ãµes matemÃ¡ticas bÃ¡sicas"),
        Tool(name="search_web", func=search_web, description="Busca informaÃ§Ãµes na web")
    ]

    # Cria agent
    agent = Agent("chatbot_agent")

    # Context para memÃ³ria conversacional
    await agent.add_component(
        ContextComponent,
        config=create_chatbot_config()
    )

    # LLM com Gemini e tools
    llm_config = LLMConfig(
        llm_id="google:gemini-2.5-flash",
        temperature=0.7,
        max_tokens=1000,
        tools=tools
    )
    await agent.add_component(LLMComponent, config=llm_config)

    # Output component
    await agent.add_component(
        OutputComponent,
        config=OutputConfig(output_format="text")
    )

    # Inicializa
    await agent.init_all()
    print("âœ… Chatbot inicializado com memÃ³ria e ferramentas!")

    # Registra no bus
    bus = EventBus()
    bus.register_agent("chatbot_agent", agent)

    # InteraÃ§Ã£o com usuÃ¡rio
    session_id = "chat_session_" + str(id(agent))  # ID Ãºnico
    print("\nğŸ’¬ Chatbot pronto! Digite mensagens ou 'sair' para finalizar.")

    while True:
        try:
            user_input = input("\nVocÃª: ")
            if user_input.lower() in ["sair", "exit", "quit"]:
                break

            print(f"ğŸ¤” Processando: {user_input[:50]}...")

            # Cria evento de input
            input_event = InputEvent(
                sender="user",
                target="chatbot_agent:ContextComponent",
                content=user_input,
                session_id=session_id
            )

            # Dispara evento no bus
            events = await bus.dispatch([input_event])

            print(f"ğŸ“‹ Eventos processados: {len(events)}")

        except KeyboardInterrupt:
            print("\nâš ï¸ InterrupÃ§Ã£o detectada")
            break
        except Exception as e:
            print(f"âŒ Erro: {e}")
            break

    # Finaliza
    await agent.shutdown_all()
    print("ğŸ›‘ Chatbot finalizado")

async def main():
    """Executa todas as demos"""
    print("ğŸ­ ECSA Component Architecture - Suite de Demos")
    print(f"Arquitetura refatorada implementando {len(open(project_root / 'main.py').readlines())} linhas de cÃ³digo")
    print("Demonstrando todos os novos recursos...\n")

    try:
        # Executa todas as demos sequencialmente
        await demo_configuration_and_presets()
        await demo_component_testing()
        await demo_component_features()
        await demo_inter_component_call()

        # Demo bÃ¡sica por Ãºltimo (mais complexo)
        await demo_basic_agent()

        # Se tem API keys, roda o chatbot interativo
        if has_api_keys:
            await demo_chatbot()

        print("\n" + "="*60)
        print("ğŸ‰ TODAS AS DEMOS CONCLUÃDAS COM SUCESSO!")
        print("="*60)
        print("\nğŸ“‹ Recursos demonstrados:")
        print("  â€¢ âœ… Lifecycle hooks (on_init, on_shutdown, on_reload)")
        print("  â€¢ ğŸ›¡ï¸ Error handling robusto com on_error hook")
        print("  â€¢ ğŸ¯ Type-safe event contracts (classes ao invÃ©s de strings)")
        print("  â€¢ ğŸ”— call_component() para comunicaÃ§Ã£o direta")
        print("  â€¢ âš™ï¸ Configuration schemas com Pydantic")
        print("  â€¢ ğŸ§° Middleware support system")
        print("  â€¢ ğŸ“Š Basic observability (mÃ©tricas)")
        print("  â€¢ ğŸ­ AsyncComponent com requests/responses tipados")
        print("  â€¢ ğŸ§ª ComponentTestHarness para testes isolados")
        print("\nğŸš€ Pronto para desenvolvimento de componentes customizados!")

    except Exception as e:
        print(f"\nâŒ Erro durante demos: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # Verifica se tem API keys (opcional para demos)
    has_api_keys = bool(
        os.getenv('GOOGLE_API_KEY') or
        os.getenv('OPENAI_API_KEY') or
        os.getenv('ANTHROPIC_API_KEY')
    )

    if not has_api_keys:
        print("âš ï¸ AVISO: Nenhuma API key encontrada. Algumas demos podem falhar.")
        print("   Configure GOOGLE_API_KEY, OPENAI_API_KEY ou ANTHROPIC_API_KEY\n")

    asyncio.run(main())
